{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle \n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pruned networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltimestamp = '2022_11_05__01_04_10'\n",
    "\n",
    "dataOutput = '/gscratch/dynamicsai/otthomas/MothPruning/mothMachineLearning_dataAndFigs/DataOutput/Experiments/pruned_bias/pruned_bias/'\n",
    "modelSubdir = os.path.join(dataOutput, modeltimestamp)\n",
    "\n",
    "zscoreOutput = '/gscratch/dynamicsai/otthomas/MothMotifs/MothMotifs/DataOutput/zscoreTables/'\n",
    "zscoreSubdir = os.path.join(zscoreOutput, modeltimestamp)\n",
    "if not os.path.exists(zscoreSubdir):\n",
    "    os.mkdir(zscoreSubdir)\n",
    "\n",
    "#Load the networks\n",
    "sparseNetsFile = 'sparseNetworks.pkl'\n",
    "sparseNetworks = pickle.load(open(os.path.join( modelSubdir, sparseNetsFile), 'rb'))\n",
    "\n",
    "masksFile = 'masks_minmax_Adam5.pkl'\n",
    "masks = pickle.load(open(os.path.join(modelSubdir, masksFile), 'rb'))\n",
    "\n",
    "bmasksFile = 'bmasks_minmax_Adam5.pkl'\n",
    "bmasks = pickle.load(open(os.path.join(modelSubdir, bmasksFile), 'rb'))\n",
    "\n",
    "#Load the losses\n",
    "losses = pickle.load(open(os.path.join(modelSubdir, 'preprocessedNets', 'pruneLosses.pkl'),'rb'))\n",
    "\n",
    "losses = np.array(losses)\n",
    "losses = np.transpose(losses)\n",
    "\n",
    "lossesDF = pd.DataFrame(losses, columns=['0%', '15%', '25%', '35%', '45%', '55%', '65%', '75%', '85%', '90%', '91%', \n",
    "                                        '92%', '93%', '94%', '95%', '96%', '97%', '98%' ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparseMasks = []\n",
    "for i in range(len(sparseNetworks)):\n",
    "    sparsity = sparseNetworks[i][0]\n",
    "    m = [masks[sparsity][j][i] for j in range(5)]\n",
    "    bm = [bmasks[sparsity][j][i] for j in range(5)]\n",
    "\n",
    "    #Combine mask and bias mask by adding bias mask as last row of mask \n",
    "    mask = [np.append(m[j], np.array(bm[j]).reshape([1, len(bm[j])]), axis=0) for j in range(5)]\n",
    "\n",
    "    sparseMasks.append((sparsity, mask))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove ghost nodes "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ghost nodes: nodes with no upstream input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmGhostNodes(masks): \n",
    "    sparseMasks_wo_ghosts = []\n",
    "    for k in range(len(masks)):\n",
    "        count = 0\n",
    "        m = masks[k][1]\n",
    "        #Iterate over the masking layers in each network \n",
    "        for i in range(len(m)):\n",
    "            #Iterate over the columns of the mask \n",
    "            for j in range(len(m[i].T)):\n",
    "                column = m[i].T[j]\n",
    "                #Check to see if there are any connections between this node and the nodes in the previous layer. \n",
    "                #If there are no connections, that means there are no upstream connections and this is a ghost node. \n",
    "                n = np.count_nonzero(column)\n",
    "                if n == 0:\n",
    "                    #print('Found a ghost node: %s node in layer %s.' % (j, i))\n",
    "                    count += 1\n",
    "                    #There is no input into this node \n",
    "                    #so make all downstream connections 0\n",
    "\n",
    "                    #i+1 gets us to the next mask \n",
    "                    #where the jth row is the ghost node \n",
    "                    m[i+1][j] = m[i+1][j] * 0\n",
    "\n",
    "        sparseMasks_wo_ghosts.append((masks[k][0],m))\n",
    "\n",
    "    pickle.dump(sparseMasks_wo_ghosts, open(os.path.join(modelSubdir, 'postprune', 'masks_wo_ghost_nodes.pkl'), 'wb'))\n",
    "\n",
    "    return sparseMasks_wo_ghosts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove dead nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dead nodes: nodes with no downstream output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmDeadNodes(masks): \n",
    "    sparseMasks_wo_dead = []\n",
    "    for k in range(len(masks)):\n",
    "        count = 0\n",
    "        m = masks[k][1]\n",
    "        #Reverse iterate over the masking layers in each network, excluding the input and output layers\n",
    "        for i in reversed(range(1, len(m))):\n",
    "            #Iterate over the rows of the mask, skipping the bias (last row)\n",
    "            for j in range(len(m[i])-1):\n",
    "                row = m[i][j]\n",
    "                #Check to see if there are any connections between this node and the nodes in the next layer. \n",
    "                #If there are no connections, that means there are no downstream connections and this is a dead node. \n",
    "                n = np.count_nonzero(row)\n",
    "                if n == 0:\n",
    "                    #print('Found a dead node: %s node in layer %s.' % (j, i))\n",
    "                    count += 1\n",
    "                    #There is no output from this node \n",
    "                    #so make all upstream connections 0\n",
    "\n",
    "                    #i-1 gets us to the previous mask \n",
    "                    #where the jth column is the ghost node \n",
    "                    m[i-1].T[j] = m[i-1].T[j] * 0\n",
    "\n",
    "        sparseMasks_wo_dead.append((masks[k][0],m))\n",
    "\n",
    "    pickle.dump(sparseMasks_wo_dead, open(os.path.join(modelSubdir, 'postprune', 'masks_wo_dead_nodes.pkl'), 'wb'))\n",
    "\n",
    "    return sparseMasks_wo_dead"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the motif z-score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motif counting functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First-order motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fom(m):\n",
    "        '''\n",
    "        Calculates the number of first-order motifs in the network (equivalent to the number of edges).\n",
    "        \n",
    "        Input(s): the mask of the pruned network, as a list of matrices\n",
    "        Returns: FOM (total number of first-order motifs), FOMList (Number of weights and number of bias connections\n",
    "                in each layer)\n",
    "        '''\n",
    "        FOM = 0\n",
    "        FOMList = [[0,0],[0,0],[0,0],[0,0],[0,0]] #[[Num weights, num biases]] in each layer\n",
    "\n",
    "        for i in range(len(m)): \n",
    "                #Count number of connections between weights\n",
    "                w_connections = np.count_nonzero(m[i][0:-1])\n",
    "                FOMList[i][0] = w_connections\n",
    "                #Count number of connections from bias\n",
    "                b_connections = np.count_nonzero(m[i][-1])\n",
    "                FOMList[i][1] = b_connections\n",
    "\n",
    "                connections = w_connections + b_connections\n",
    "                FOM += connections\n",
    "        return FOM, FOMList"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second-order motifs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diverging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sodm(m):\n",
    "    '''\n",
    "    Calculates the number of second-order diverging motifs in the network.\n",
    "    Also calculates the remaining number of nodes in the network. \n",
    "        \n",
    "    Input(s): the mask of the pruned network, as a list of matrices\n",
    "    Returns: SODM (total number of second-order diverging motifs in the network), numFC (Number of remaining nodes \n",
    "        with downstream output)\n",
    "    '''\n",
    "    \n",
    "    SODM = 0\n",
    "    numFC = [0,0,0,0,0,0] #Number of remaining nodes with downstream output\n",
    "\n",
    "    for i in range(len(m)): \n",
    "        nodes = 0\n",
    "        #Calculate second-order diverging motifs\n",
    "        for row in m[i]:\n",
    "            n = np.count_nonzero(row)\n",
    "            if n >= 2:\n",
    "                SODM += math.factorial(n)/(math.factorial(2)*math.factorial(n-2))\n",
    "                    \n",
    "            #also calculate number of remaining nodes\n",
    "            if n > 0: \n",
    "                nodes += 1\n",
    "                    \n",
    "        numFC[i] = nodes\n",
    "            \n",
    "            #Count number of nodes in final layer \n",
    "        if i == 4: \n",
    "            nodes = 0 \n",
    "            for row in m[i].T:\n",
    "                n = np.count_nonzero(row)\n",
    "                if n > 0 :\n",
    "                    nodes += 1\n",
    "            numFC[i+1] = nodes\n",
    "    \n",
    "    return SODM, numFC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def socm(m):\n",
    "    '''\n",
    "    Calculates the number of second-order converging motifs in the network.\n",
    "        \n",
    "    Input(s): the mask of the pruned network, as a list of matrices\n",
    "    Returns: SOCM (total number of second-order converging motifs in the network)\n",
    "    '''\n",
    "\n",
    "    SOCM = 0\n",
    "    numFCUS = [0,0,0,0,0,0]\n",
    "\n",
    "    for i in range(len(m)):\n",
    "        nodes = 0\n",
    "        #Calculate second-order converging motifs\n",
    "        for column in m[i].T:\n",
    "            n = np.count_nonzero(column)\n",
    "            if n >= 2:\n",
    "                SOCM += math.factorial(n)/(math.factorial(2)*math.factorial(n-2))\n",
    "\n",
    "            \n",
    "            #also calculate number of remaining nodes with upstream input, skip input \n",
    "            if n > 0: \n",
    "                nodes += 1\n",
    "                    \n",
    "        numFCUS[i+1] = nodes\n",
    "\n",
    "    return SOCM, numFCUS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sochain(m):\n",
    "    '''\n",
    "    Calculates the number of second-order chain motifs in the network.\n",
    "        \n",
    "    Input(s): the mask of the pruned network, as a list of matrices\n",
    "    Returns: SOChain (total number of second-order chain motifs in the network)\n",
    "    ''' \n",
    "    \n",
    "    SOChain = 0 \n",
    "    for i in range(len(m)): \n",
    "        #Calculate second-order chain motifs\n",
    "        if i != 4: \n",
    "            #Exclude the bias by excluding the last row\n",
    "            SOChain += np.count_nonzero(np.matmul(m[i][0:-1],m[i+1][0:-1]))\n",
    "            \n",
    "            #Add in the motifs from the bias terms \n",
    "            SOChain += np.count_nonzero(np.matmul(m[i][-1],m[i+1][0:-1]))\n",
    "        else: \n",
    "            pass\n",
    "\n",
    "    return SOChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third-order motifs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diverging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def todm(m):\n",
    "    '''\n",
    "    Calculates the number of third-order diverging motifs in the network.\n",
    "        \n",
    "    Input(s): the mask of the pruned network, as a list of matrices\n",
    "    Returns: TODM (total number of third-order diverging motifs in the network)\n",
    "    '''\n",
    "\n",
    "    TODM = 0 \n",
    "    for i in range(len(m)): \n",
    "        #Calculate third-order diverging motifs\n",
    "        for row in m[i]:\n",
    "            n = np.count_nonzero(row)\n",
    "            if n >= 3:\n",
    "                TODM += math.factorial(n)/(math.factorial(3)*math.factorial(n-3))\n",
    "\n",
    "    return TODM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tocm(m):\n",
    "    '''\n",
    "    Calculates the number of third-order converging motifs in the network.\n",
    "        \n",
    "    Input(s): the mask of the pruned network, as a list of matrices\n",
    "    Returns: TOCM (total number of third-order converging motifs in the network)\n",
    "    '''\n",
    "\n",
    "    TOCM = 0 \n",
    "    for i in range(len(m)): \n",
    "        #Calculate third-order converging motifs \n",
    "        for column in m[i].T:\n",
    "            n = np.count_nonzero(column)\n",
    "            if n >= 3:\n",
    "                TOCM += math.factorial(n)/(math.factorial(2)*math.factorial(n-2))\n",
    "\n",
    "    return TOCM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tochain(m):\n",
    "    '''\n",
    "    Calculates the number of third-order chain motifs in the network.\n",
    "        \n",
    "    Input(s): the mask of the pruned network, as a list of matrices\n",
    "    Returns: TOChain (total number of third-order chain motifs in the network)\n",
    "    '''\n",
    "\n",
    "    TOChain = 0\n",
    "    for i in range(len(m)): \n",
    "        #Calculate third-order chain motifs \n",
    "        if i in (0,1,2): \n",
    "            #Count non-zero elements of (Layer 1 * Layer 2 * Layer 3)\n",
    "            #Exclude the bias by excluding the last row\n",
    "            m1 = np.matmul(m[i][0:-1],m[i+1][0:-1])\n",
    "            TOChain += np.count_nonzero(np.matmul(m1,m[i+2][0:-1]))\n",
    "                \n",
    "            #Add in the motifs from the bias terms \n",
    "            mbias = np.matmul(m[i][-1],m[i+1][0:-1])\n",
    "            TOChain += np.count_nonzero(np.matmul(mbias,m[i+2][0:-1]))\n",
    "        else: \n",
    "            pass\n",
    "\n",
    "    return TOChain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bifan(m):\n",
    "    '''\n",
    "    Calculates the number of bi-fan motifs in the network.\n",
    "        \n",
    "    Input(s): the mask of the pruned network, as a list of matrices\n",
    "    Returns: BIFAN (total number of bi-fan motifs in the network)\n",
    "    '''\n",
    "    \n",
    "    BIFAN = 0\n",
    "\n",
    "    for i in range(len(m)): \n",
    "        #For each row, calculate the dot product of the row with the rest of the rows in the mask \n",
    "        for j in range(len(m[i])-1):\n",
    "            row = m[i][j]\n",
    "            mat = m[i][j+1:]\n",
    "            count = np.dot(mat, row) #Each element in count represents the number of bifans row j shares with all subsequent rows \n",
    "\n",
    "            #Calculate the number of bifans\n",
    "            for n in count: \n",
    "                n = int(n)\n",
    "                if n >= 2: \n",
    "                    BIFAN += math.factorial(n)/(math.factorial(2)*math.factorial(n-2))\n",
    "    \n",
    "    return BIFAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build random network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildRandomNet(numFC, FOMList):\n",
    "    '''\n",
    "    Builds randomly connected network with the same number of weights and bias connections as the real network. \n",
    "\n",
    "    Input(s): numFC (Number of remaining nodes with downstream output), FOMList (Number of weights and number of \n",
    "        bias connections in each layer)\n",
    "    Returns: the mask of the random network, as a list of matrices\n",
    "    '''\n",
    "    #random weight matrix = np.array(([1]*num connections between weights)+\n",
    "    #                       [0]*(num possible connections - num connections between weights))\n",
    "    #           numFC[0]-1 because we need to discount bias \n",
    "    r1 = np.array([1] * (FOMList[0][0]) + [0] * (((numFC[0]-1)*(numFC[1]-1))-(FOMList[0][0])))\n",
    "    #random bias matrix = np.array(([1]*num connections between bias and next nodes)+\n",
    "    #                       [0]*(num possible connections - num connections between bias and next nodes))\n",
    "\n",
    "    #There is always a live bias, so number of possible connections between bias and next\n",
    "    #   layer would be numFC[i+1]-1 (to remove bias).\n",
    "    r1b = np.array([1] * FOMList[0][1] + [0] * ((numFC[1]-1)-FOMList[0][1]))\n",
    "\n",
    "    r2 = np.array([1] * (FOMList[1][0]) + [0] * (((numFC[1]-1)*(numFC[2]-1))-(FOMList[1][0])))\n",
    "    r3 = np.array([1] * (FOMList[2][0]) + [0] * (((numFC[2]-1)*(numFC[3]-1))-(FOMList[2][0])))\n",
    "    r4 = np.array([1] * (FOMList[3][0]) + [0] * (((numFC[3]-1)*(numFC[4]-1))-(FOMList[3][0])))\n",
    "    r5 = np.array([1] * (FOMList[4][0]) + [0] * (((numFC[4]-1)*(numFC[5]))-(FOMList[4][0]))) #no bias in last layer\n",
    "\n",
    "    r2b = np.array([1] * FOMList[1][1] + [0] * ((numFC[2]-1)-FOMList[1][1]))\n",
    "    r3b = np.array([1] * FOMList[2][1] + [0] * ((numFC[3]-1)-FOMList[2][1]))\n",
    "    r4b = np.array([1] * FOMList[3][1] + [0] * ((numFC[4]-1)-FOMList[3][1]))\n",
    "    r5b = np.array([1] * FOMList[4][1] + [0] * ((numFC[5])-FOMList[4][1]))\n",
    "        \n",
    "    np.random.shuffle(r1)\n",
    "    np.random.shuffle(r2)\n",
    "    np.random.shuffle(r3)\n",
    "    np.random.shuffle(r4)\n",
    "    np.random.shuffle(r5)\n",
    "\n",
    "    np.random.shuffle(r1b)\n",
    "    np.random.shuffle(r2b)\n",
    "    np.random.shuffle(r3b)\n",
    "    np.random.shuffle(r4b)\n",
    "    np.random.shuffle(r5b)\n",
    "            \n",
    "    randomNet = [np.vstack([np.reshape(r1, (((numFC[0]-1),(numFC[1]-1)))),r1b]),\n",
    "                np.vstack([np.reshape(r2, (((numFC[1]-1),(numFC[2]-1)))),r2b]),\n",
    "                np.vstack([np.reshape(r3, (((numFC[2]-1),(numFC[3]-1)))),r3b]),\n",
    "                np.vstack([np.reshape(r4, (((numFC[3]-1),(numFC[4]-1)))),r4b]),\n",
    "                np.vstack([np.reshape(r5, (((numFC[4]-1),(numFC[5])))),r5b])]\n",
    "\n",
    "    return randomNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find motifs for random networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomNetMotifs(randomNet):\n",
    "    '''\n",
    "    Finds all of the motifs for the random network.\n",
    "\n",
    "    Input(s): the mask of the random network, as a list of matrices\n",
    "    Returns: rFOM (random first-order motifs), rFOMList (remaining connections in each layer), rSODM (random second-oder \n",
    "        diverging motifs), rSOCM (random second-order converging motifs), rSOChain (random second-order chain motifs), \n",
    "        rTODM (random third-order diverging motifs), rTOCM (random third-order converging motifs), rTOChain (random \n",
    "        third-order chain motifs)\n",
    "    '''\n",
    "\n",
    "    rFOM, rFOMList = fom(randomNet)\n",
    "    rSODM, rnumFC = sodm(randomNet)\n",
    "    rSOCM, rnumFCUS = socm(randomNet)\n",
    "    rSOChain = sochain(randomNet)\n",
    "    rTODM = todm(randomNet)\n",
    "    rTOCM = tocm(randomNet)\n",
    "    rTOChain = tochain(randomNet)\n",
    "    rBIFAN = bifan(randomNet)\n",
    "    \n",
    "    return rFOM, rFOMList, rSODM, rSOCM, rSOChain, rTODM, rTOCM, rTOChain, rBIFAN, rnumFC, rnumFCUS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average random motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildRandomMotifsDF(numFC, FOMList, numRand=1000):\n",
    "    '''\n",
    "    Builds dataframe of numRand number of random network motif counts. \n",
    "    To calculate the z-score, we need to compare the real network to many randomly generated networks. This function \n",
    "        adds all of that information to a dataframe. \n",
    "\n",
    "    Input(s): numFC (Number of remaining nodes with downstream output), FOMList (Number of weights and number of \n",
    "        bias connections in each layer), numRand=1000 (number of random networks we want to generate, default 1000)\n",
    "    Returns: random network motif dataframe\n",
    "    '''\n",
    "    randomNetDF = pd.DataFrame(columns=['rSODM',\n",
    "                                        'rSOCM',\n",
    "                                        'rSOChain',\n",
    "                                        'rTODM',\n",
    "                                        'rTOCM', \n",
    "                                        'rTOChain',\n",
    "                                        'rBIFAN',\n",
    "                                        'rnumFC',\n",
    "                                        'rnumFCUS'])\n",
    "\n",
    "    for r in range(numRand):\n",
    "        randomNet = buildRandomNet(numFC, FOMList)\n",
    "        rFOM, rFOMList, rSODM, rSOCM, rSOChain, rTODM, rTOCM, rTOChain, rBIFAN, rnumFC, rnumFCUS = randomNetMotifs(randomNet)\n",
    "\n",
    "        rMotifs = [float(rSODM), float(rSOCM), float(rSOChain), float(rTODM), float(rTOCM), float(rTOChain), float(rBIFAN), rnumFC, rnumFCUS]\n",
    "        randomNetDF.loc[len(randomNetDF.index)] = rMotifs\n",
    "\n",
    "    return randomNetDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove ghost and dead nodes from the networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparseMasks_wo_G = rmGhostNodes(sparseMasks)\n",
    "sparseMasks_wo_G_D = rmDeadNodes(sparseMasks_wo_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscoreDF = pd.DataFrame(columns=['Sparsity Index', 'Masks',\n",
    "                                '1-O motifs (real)', \n",
    "                                'S-O diverging motifs (real)', 'S-O converging motifs (real)', \n",
    "                                'S-O chain motifs (real)',  'T-O chain motifs (real)',\n",
    "                                'T-O diverging motifs (real)', 'T-O converging motifs (real)',\n",
    "                                'T-O Bi-Fan motifs (real)',\n",
    "                                \n",
    "                                'Avg - S-O diverging motifs (random)', 'Avg - S-O converging motifs (random)', \n",
    "                                'Avg - S-O chain motifs (random)',  'Avg - T-O chain motifs (random)',\n",
    "                                'Avg - T-O diverging motifs (random)', 'Avg - T-O converging motifs (random)',\n",
    "                                'Avg - T-O Bi-Fan motifs',\n",
    "\n",
    "                                 \n",
    "                                'SD - S-O diverging motifs (random)', 'SD - S-O converging motifs (random)', \n",
    "                                'SD - S-O chain motifs (random)',  'SD - T-O chain motifs (random)',\n",
    "                                'SD - T-O diverging motifs (random)', 'SD - T-O converging motifs (random)',\n",
    "                                'SD - T-O Bi-Fan motifs',\n",
    "                                \n",
    "                                'Z - S-O diverging motifs', 'Z - S-O converging motifs', \n",
    "                                'Z - S-O chain motifs',  'Z - T-O chain motifs',\n",
    "                                'Z - T-O diverging motifs', 'Z - T-O converging motifs',\n",
    "                                'Z - T-O Bi-Fan motifs',\n",
    "\n",
    "                                'Number of nodes in each layer with downstream output',\n",
    "                                'Number of nodes in each layer with upstream input', \n",
    "                                'Number of connections in each layer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (sparsity, m) in sparseMasks_wo_G_D: \n",
    "    FOM, FOMList = fom(m)\n",
    "    SODM, numFC = sodm(m)\n",
    "    SOCM, numFCUS = socm(m)\n",
    "    SOChain = sochain(m)\n",
    "    TODM = todm(m)\n",
    "    TOCM = tocm(m)\n",
    "    TOChain = tochain(m)\n",
    "    BIFAN = bifan(m)\n",
    "\n",
    "    randomNetDF = buildRandomMotifsDF(numFC, FOMList, numRand=1000)\n",
    "\n",
    "    AvgrSODM = randomNetDF['rSODM'].mean()\n",
    "    AvgrSOCM = randomNetDF['rSOCM'].mean()\n",
    "    AvgrSOChain = randomNetDF['rSOChain'].mean()\n",
    "    AvgrTODM = randomNetDF['rTODM'].mean()\n",
    "    AvgrTOCM = randomNetDF['rTOCM'].mean()\n",
    "    AvgrTOChain = randomNetDF['rTOChain'].mean()\n",
    "    AvgrBIFAN = randomNetDF['rBIFAN'].mean()\n",
    "\n",
    "    SDrSODM = randomNetDF['rSODM'].std()\n",
    "    SDrSOCM = randomNetDF['rSOCM'].std()\n",
    "    SDrSOChain = randomNetDF['rSOChain'].std()\n",
    "    SDrTODM = randomNetDF['rTODM'].std()\n",
    "    SDrTOCM = randomNetDF['rTOCM'].std()\n",
    "    SDrTOChain = randomNetDF['rTOChain'].std()\n",
    "    SDrBIFAN = randomNetDF['rBIFAN'].std()\n",
    "\n",
    "    ZSODM = (SODM - AvgrSODM)/SDrSODM\n",
    "    ZSOCM = (SOCM - AvgrSOCM)/SDrSOCM\n",
    "    ZSOChain = (SOChain - AvgrSOChain)/SDrSOChain\n",
    "    ZTODM = (TODM - AvgrTODM)/SDrTODM\n",
    "    ZTOCM = (TOCM - AvgrTOCM)/SDrTOCM\n",
    "    ZTOChain = (TOChain - AvgrTOChain)/SDrTOChain\n",
    "    ZBIFAN = (BIFAN - AvgrBIFAN)/SDrBIFAN\n",
    "\n",
    "    zscoreData = [float(sparsity), m, \n",
    "                    float(FOM), \n",
    "                    float(SODM), float(SOCM), float(SOChain),\n",
    "                    float(TODM), float(TOCM), float(TOChain),\n",
    "                    float(BIFAN),\n",
    "\n",
    "                    float(AvgrSODM), float(AvgrSOCM), float(AvgrSOChain),\n",
    "                    float(AvgrTODM), float(AvgrTOCM), float(AvgrTOChain),\n",
    "                    float(AvgrBIFAN),\n",
    "\n",
    "                    float(SDrSODM), float(SDrSOCM), float(SDrSOChain),\n",
    "                    float(SDrTODM), float(SDrTOCM), float(SDrTOChain),\n",
    "                    float(SDrBIFAN),\n",
    "\n",
    "                    float(ZSODM), float(ZSOCM), float(ZSOChain),\n",
    "                    float(ZTODM), float(ZTOCM), float(ZTOChain),\n",
    "                    float(ZBIFAN),\n",
    "\n",
    "                    numFC, numFCUS, FOMList]\n",
    "\n",
    "    zscoreDF.loc[len(zscoreDF.index)] = zscoreData\n",
    "\n",
    "    zscoreDF.to_csv(os.path.join(zscoreSubdir, 'zscoreDF.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Nov 16 2022, 15:31:39) \n[GCC 8.5.0 20210514 (Red Hat 8.5.0-15)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
